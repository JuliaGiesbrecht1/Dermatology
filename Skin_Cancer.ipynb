{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1XSPT2g+zxQZt5iBMV32d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuliaGiesbrecht1/Dermatology/blob/main/Skin_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XSB30F2GnjMU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.utils import get_file\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
        "from imblearn.metrics import sensitivity_score, specificity_score\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "# to get consistent results after multiple runs\n",
        "tf.random.set_seed(7)\n",
        "np.random.seed(7)\n",
        "random.seed(7)\n",
        "\n",
        "# 0 for benign, 1 for malignant\n",
        "class_names = [\"benign\", \"malignant\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract_dataset():\n",
        "  # dataset from https://github.com/udacity/dermatologist-ai\n",
        "  # 5.3GB\n",
        "  train_url = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/train.zip\"\n",
        "  # 824.5MB\n",
        "  valid_url = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/valid.zip\"\n",
        "  # 5.1GB\n",
        "  test_url  = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/test.zip\"\n",
        "  for i, download_link in enumerate([valid_url, train_url, test_url]):\n",
        "    temp_file = f\"temp{i}.zip\"\n",
        "    data_dir = get_file(origin=download_link, fname=os.path.join(os.getcwd(), temp_file))\n",
        "    print(\"Extracting\", download_link)\n",
        "    with zipfile.ZipFile(data_dir, \"r\") as z:\n",
        "      z.extractall(\"data\")\n",
        "    # remove the temp file\n",
        "    os.remove(temp_file)\n",
        "\n",
        "# comment the below line if you already downloaded the dataset\n",
        "# download_and_extract_dataset()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jgTkSgknoEq",
        "outputId": "a7c0e6bf-bc0e-4509-a0fb-11fe5ad344f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/valid.zip\n",
            "864538487/864538487 [==============================] - 18s 0us/step\n",
            "Extracting https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/valid.zip\n",
            "Downloading data from https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/train.zip\n",
            "5736557430/5736557430 [==============================] - 127s 0us/step\n",
            "Extracting https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/train.zip\n",
            "Downloading data from https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/test.zip\n",
            "5528640507/5528640507 [==============================] - 126s 0us/step\n",
            "Extracting https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/test.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing Data\n",
        "\n",
        "def generate_csv(folder, label2int):\n",
        "\n",
        "    # Extracting the basename of the folder\n",
        "    # These will be used to name the output CSV files\n",
        "    folder_name = os.path.basename(folder)\n",
        "\n",
        "    # Converting keys from dictionary into list of the labels\n",
        "    labels = list(label2int)\n",
        "\n",
        "    # Initializing an empty pandas dataframe\n",
        "    df = pd.DataFrame(columns=[\"filepath\", \"label\"])\n",
        "\n",
        "    # Used for indexing rows for the dataframe\n",
        "    i = 0\n",
        "    for label in labels:\n",
        "        print(\"Reading\", os.path.join(folder, label, \"*\"))\n",
        "\n",
        "        # for each label, finds the coresponding file in the folder\n",
        "        # example label is \"nevus\", finds folder \"nevus\"\n",
        "        for filepath in glob.glob(os.path.join(folder, label, \"*\")):\n",
        "\n",
        "            # Adds a new row to the DataFrame with the filepath and the numeric label.\n",
        "            df.loc[i] = [filepath, label2int[label]]\n",
        "            i += 1\n",
        "\n",
        "    output_file = f\"{folder_name}.csv\"\n",
        "    print(\"Saving\", output_file)\n",
        "    df.to_csv(output_file)\n",
        "\n",
        "# generate CSV files for all data portions, labeling nevus and seborrheic keratosis\n",
        "# as 0 (benign), and melanoma as 1 (malignant)\n",
        "generate_csv(\"data/train\", {\"nevus\": 0, \"seborrheic_keratosis\": 0, \"melanoma\": 1})\n",
        "generate_csv(\"data/valid\", {\"nevus\": 0, \"seborrheic_keratosis\": 0, \"melanoma\": 1})\n",
        "generate_csv(\"data/test\", {\"nevus\": 0, \"seborrheic_keratosis\": 0, \"melanoma\": 1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-oP0GUvusvU",
        "outputId": "ffd785d8-8dd5-43ce-c214-b06c66a991a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data/train/nevus/*\n",
            "Reading data/train/seborrheic_keratosis/*\n",
            "Reading data/train/melanoma/*\n",
            "Saving train.csv\n",
            "Reading data/valid/nevus/*\n",
            "Reading data/valid/seborrheic_keratosis/*\n",
            "Reading data/valid/melanoma/*\n",
            "Saving valid.csv\n",
            "Reading data/test/nevus/*\n",
            "Reading data/test/seborrheic_keratosis/*\n",
            "Reading data/test/melanoma/*\n",
            "Saving test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "-F09QZhwxwuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label2int = {\"nevus\": 0, \"seborrheic_keratosis\": 0, \"melanoma\": 1}\n",
        "\n",
        "labels = list(label2int)\n",
        "\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyMS0_IThYAZ",
        "outputId": "49f25ee8-e431-4661-d288-aae1f6238b36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nevus', 'seborrheic_keratosis', 'melanoma']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading data\n",
        "train_metadata_filename = \"train.csv\"\n",
        "valid_metadata_filename = \"valid.csv\"\n",
        "# load CSV files as DataFrames\n",
        "df_train = pd.read_csv(train_metadata_filename)\n",
        "df_valid = pd.read_csv(valid_metadata_filename)\n",
        "n_training_samples = len(df_train)\n",
        "n_validation_samples = len(df_valid)\n",
        "print(\"Number of training samples:\", n_training_samples)\n",
        "print(\"Number of validation samples:\", n_validation_samples)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((df_train[\"filepath\"], df_train[\"label\"]))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((df_valid[\"filepath\"], df_valid[\"label\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcUDN558uweY",
        "outputId": "2c996afd-1ed6-417c-c997-fef2e53c0efc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 2000\n",
            "Number of validation samples: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [299, 299])\n",
        "\n",
        "\n",
        "def process_path(filepath, label):\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(filepath)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "\n",
        "\n",
        "valid_ds = valid_ds.map(process_path)\n",
        "train_ds = train_ds.map(process_path)\n",
        "# test_ds = test_ds\n",
        "for image, label in train_ds.take(1):\n",
        "    print(\"Image shape:\", image.shape)\n",
        "    print(\"Label:\", label.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G5uI2uEZwxn",
        "outputId": "b0ba4039-53f9-473a-ca22-e171027a1255"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (299, 299, 3)\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training parameters\n",
        "batch_size = 64\n",
        "optimizer = \"rmsprop\"\n",
        "\n",
        "def prepare_for_training(ds, cache=True, batch_size=64, shuffle_buffer_size=1000):\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "  # shuffle the dataset\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "  # split to batches\n",
        "  ds = ds.batch(batch_size)\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "valid_ds = prepare_for_training(valid_ds, batch_size=batch_size, cache=\"valid-cached-data\")\n",
        "train_ds = prepare_for_training(train_ds, batch_size=batch_size, cache=\"train-cached-data\")"
      ],
      "metadata": {
        "id": "mMM3RUG1Zx0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(valid_ds))\n",
        "\n",
        "def show_batch(batch):\n",
        "  plt.figure(figsize=(12,12))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(batch[0][n])\n",
        "      plt.title(class_names[batch[1][n].numpy()].title())\n",
        "      plt.axis('off')\n",
        "\n",
        "show_batch(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "STMVMGDIZ3EP",
        "outputId": "008ce175-a06e-4f51-82dd-bc995dd85c91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    773\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3028\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3029\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5887\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5888\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} End of sequence [Op:IteratorGetNext] name: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-68630c23a88b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    }
  ]
}